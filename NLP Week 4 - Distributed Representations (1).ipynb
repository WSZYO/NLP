{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da1d93ff",
   "metadata": {},
   "source": [
    "# NLP Week 4: Distributed Representations part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4822c3",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Understand-some-key-terms:\" data-toc-modified-id=\"Understand-some-key-terms:-1\">Understand some key terms:</a></span></li><li><span><a href=\"#Word-Embeddings\" data-toc-modified-id=\"Word-Embeddings-2\">Word Embeddings</a></span></li><li><span><a href=\"#Pre-trained-word-embeddings-using-gensim\" data-toc-modified-id=\"Pre-trained-word-embeddings-using-gensim-3\">Pre-trained word embeddings using gensim</a></span></li><li><span><a href=\"#Getting-the-embedding-representation-for-full-text\" data-toc-modified-id=\"Getting-the-embedding-representation-for-full-text-4\">Getting the embedding representation for full text</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3cf7ba",
   "metadata": {},
   "source": [
    "## Understand some key terms:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c96a393",
   "metadata": {},
   "source": [
    "- <b> Distributional similarity </b>\n",
    "\n",
    "    - This is the idea that the meaning of a word can be understood from the context in which the word appears. \n",
    "    - This is also known as connotation: meaning is defined by context. \n",
    "    - This is opposed to denotation: the literal meaning of any word. \n",
    "    - For example: “NLP rocks.” The literal meaning of the word “rocks” is “stones,” but from the context, it’s used to refer to something good and fashionable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51fa5ad",
   "metadata": {},
   "source": [
    "- <b> Distributional hypothesis </b>\n",
    "    - In linguistics, this hypothesizes that words that occur in similar contexts have similar meanings. \n",
    "    - For example, the English words “dog” and “cat” occur in similar contexts.\n",
    "    - Now, following from VSM, the meaning of a word is represented by the vector. Thus, if two words often occur in similar context, then their corresponding representation vectors must also be close to each other"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d58429",
   "metadata": {},
   "source": [
    "- <b>Distributional representation </b>\n",
    "Mathematically, distributional representation schemes use high-dimensional vectors to represent words. These vectors are obtained from a co-occurrence matrix that captures co-occurrence of word and context. The dimension of this matrix is equal to the size of the vocabulary of the corpus. The four schemes that we’ve seen so far—one-hot, bag of words, bag of n-grams, and TF-IDF—all fall under the umbrella of distributional representation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0d2706",
   "metadata": {},
   "source": [
    "- <b> Distributed representation </b>\n",
    "This is a related concept. It, too, is based on the distributional hypothesis. As discussed in the previous paragraph, the vectors in distributional representation are very high dimensional and sparse. This makes them computationally inefficient\n",
    "and hampers learning. To alleviate this, distributed representation schemes significantly compress the dimensionality. This results in vectors that are compact(i.e., low dimensional) and dense (i.e., hardly any zeros). The resulting vector\n",
    "space is known as distributed representation. All the subsequent schemes we’ll discuss in this chapter are examples of distributed representation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77324929",
   "metadata": {},
   "source": [
    "- <b> Embedding </b>\n",
    "For the set of words in a corpus, embedding is a mapping between vector space\n",
    "coming from distributional representation to vector space coming from distributed representation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1205992",
   "metadata": {},
   "source": [
    "- <b> Vector semantics </b>\n",
    "This refers to the set of NLP methods that aim to learn the word representations\n",
    "based on distributional properties of words in a large corpus.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1637dd9b",
   "metadata": {},
   "source": [
    "## Word Embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e406c6",
   "metadata": {},
   "source": [
    "Let’s consider some examples. If we’re given the word “USA,” distributionally similar words could be other countries (e.g., Canada, Germany, India, etc.) or cities in the USA.\n",
    "In 2013, a seminal work by Mikolov et al. showed that their neural network–based word representation model known as “Word2vec,” based on “distributional similarity,” can capture word analogy relationships such as:\n",
    "King – Man + Woman ≈ Queen\n",
    "\n",
    "While learning such semantically rich relationships, Word2vec ensures that the\n",
    "learned word representations are low dimensional (vectors of dimensions 50–500,\n",
    "instead of several thousands, as with previously studied representations in this chapter) and dense (that is, most values in these vectors are non-zero). Such representa‐\n",
    "tions make ML tasks more tractable and efficient.\n",
    "\n",
    "To “derive” the meaning of the word, Word2vec uses distributional similarity and distributional hypothesis. That is, it derives the meaning of a word from its context:\n",
    "words that appear in its neighborhood in the text. So, if two different words (often)\n",
    "occur in similar context, then it’s highly likely that their meanings are also similar.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706032d4",
   "metadata": {},
   "source": [
    "Word2vec operationalizes this by projecting the meaning of the words in a vector\n",
    "space where words with similar meanings will tend to cluster together, and words\n",
    "with very different meanings are far from one another."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5759bfd",
   "metadata": {},
   "source": [
    "## Pre-trained word embeddings using gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc87f171",
   "metadata": {},
   "source": [
    "Pre-trained word embeddings can be thought of as a large collection of key-value pairs, where keys are\n",
    "the words in the vocabulary and values are their corresponding word vectors. \n",
    "\n",
    "\n",
    "Some of the most popular pre-trained embeddings are Word2vec by Google, GloVe by\n",
    "Stanford, and fasttext embeddings by Facebook , to name a few. Further,\n",
    "they’re available for various dimensions like d = 25, 50, 100, 200, 300, 600."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da0c287d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.32 seconds taken to load model\n",
      "The len of the vocab is:  3000000\n",
      "<class 'gensim.models.keyedvectors.KeyedVectors'>\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "import time\n",
    "\n",
    "# Path of the downloaded google word2vec\n",
    "pretrainedpath = \"GoogleNews-vectors-negative300.bin\"\n",
    "\n",
    "#Start the timer\n",
    "start_time = time.time() \n",
    "\n",
    "# Load model\n",
    "w2v_model = KeyedVectors.load_word2vec_format(pretrainedpath, binary=True)\n",
    "\n",
    "#Calculate the total time elapsed to load the model\n",
    "print(\"%0.2f seconds taken to load model\"%float(time.time() - start_time)) \n",
    "\n",
    "#Number of words in the vocabulary\n",
    "print(\"The len of the vocab is: \", len(w2v_model.key_to_index)) \n",
    "print(type(w2v_model))\n",
    "print(type(w2v_model.key_to_index)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a02f21ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar words to the word happy are [('glad', 0.7408890724182129), ('pleased', 0.6632170677185059), ('ecstatic', 0.6626911163330078), ('overjoyed', 0.6599287390708923), ('thrilled', 0.6514049768447876), ('satisfied', 0.6437950134277344), ('proud', 0.636042058467865), ('delighted', 0.627237856388092), ('disappointed', 0.6269949674606323), ('excited', 0.6247665882110596)]\n",
      "300\n",
      "[-5.18798828e-04  1.60156250e-01  1.60980225e-03  2.53906250e-02\n",
      "  9.91210938e-02 -8.59375000e-02  3.24218750e-01 -2.17285156e-02\n",
      "  1.34765625e-01  1.10351562e-01 -1.04980469e-01 -2.90527344e-02\n",
      " -2.38037109e-02 -4.02832031e-02 -3.68652344e-02  2.32421875e-01\n",
      "  3.20312500e-01  1.01074219e-01  5.83496094e-02 -2.91824341e-04\n",
      " -3.29589844e-02  2.11914062e-01  4.32128906e-02 -8.59375000e-02\n",
      "  2.81250000e-01 -1.78222656e-02  3.79943848e-03 -1.71875000e-01\n",
      "  2.06054688e-01 -1.85546875e-01  3.73535156e-02 -1.21459961e-02\n",
      "  2.04101562e-01 -3.80859375e-02  3.61328125e-02 -8.15429688e-02\n",
      "  8.44726562e-02  9.37500000e-02  1.44531250e-01  7.42187500e-02\n",
      "  2.51953125e-01 -7.91015625e-02  8.69140625e-02  1.58691406e-02\n",
      "  1.09375000e-01 -2.23632812e-01 -5.15747070e-03  1.68945312e-01\n",
      " -1.36718750e-01 -2.51464844e-02 -3.85742188e-02 -1.33056641e-02\n",
      "  1.38671875e-01  1.76757812e-01  1.10351562e-01  1.51367188e-01\n",
      "  7.86132812e-02 -1.69921875e-01  1.20605469e-01 -4.37500000e-01\n",
      " -4.32128906e-02  1.34765625e-01 -3.45703125e-01  9.13085938e-02\n",
      "  4.71191406e-02  9.66796875e-02 -1.61132812e-02 -4.71191406e-02\n",
      " -4.68750000e-02  1.37695312e-01  9.96093750e-02  4.49218750e-02\n",
      " -2.49023438e-02  1.58203125e-01 -3.57421875e-01 -1.21093750e-01\n",
      "  1.15722656e-01  9.08203125e-02  1.40625000e-01  1.60156250e-01\n",
      " -4.42504883e-03  5.34667969e-02  2.28515625e-01  1.88476562e-01\n",
      " -3.88183594e-02 -2.53906250e-01 -1.74804688e-01  9.81445312e-02\n",
      "  1.08642578e-02  1.41601562e-01  7.81250000e-03  1.36718750e-01\n",
      " -2.08007812e-01 -3.41796875e-02 -2.50000000e-01  1.25976562e-01\n",
      "  1.57226562e-01  3.31115723e-03 -1.51367188e-01 -6.98242188e-02\n",
      " -1.40625000e-01  2.06054688e-01 -3.54003906e-02  1.57226562e-01\n",
      "  5.83496094e-02 -3.58886719e-02  2.12890625e-01 -1.13769531e-01\n",
      "  1.41601562e-01 -1.29394531e-02  9.13085938e-02 -3.95507812e-02\n",
      "  9.76562500e-02 -2.69775391e-02  1.30004883e-02 -1.30859375e-01\n",
      "  3.32031250e-01 -3.53515625e-01 -5.44433594e-02 -2.50244141e-02\n",
      " -1.42578125e-01  6.49414062e-02  5.54199219e-02 -4.83398438e-02\n",
      " -1.12304688e-01 -1.32812500e-01 -6.73828125e-02 -1.41601562e-01\n",
      " -2.05078125e-01 -1.29882812e-01 -1.04003906e-01 -8.10546875e-02\n",
      " -1.67968750e-01  1.63085938e-01 -1.13769531e-01 -5.17578125e-02\n",
      "  7.61718750e-02  3.59375000e-01  1.04003906e-01  3.59375000e-01\n",
      " -8.74023438e-02  6.54296875e-02 -1.09863281e-02 -1.88476562e-01\n",
      " -6.59179688e-02  2.30468750e-01 -2.96875000e-01  6.59179688e-03\n",
      "  1.49414062e-01 -1.73828125e-01  1.31835938e-01  2.36328125e-01\n",
      " -9.22851562e-02  1.70898438e-01 -1.70898438e-02  3.12500000e-02\n",
      " -3.37219238e-03  9.66796875e-02 -2.61718750e-01 -1.84326172e-02\n",
      " -1.85546875e-01  1.24023438e-01  3.00781250e-01  2.43164062e-01\n",
      "  3.06640625e-01 -3.28125000e-01 -5.05371094e-02  1.01562500e-01\n",
      "  7.86132812e-02 -1.44531250e-01 -1.25976562e-01 -2.41699219e-02\n",
      "  2.94921875e-01 -1.50390625e-01 -3.97949219e-02  2.75390625e-01\n",
      "  1.26953125e-01 -9.86328125e-02 -1.39648438e-01  2.52685547e-02\n",
      " -8.54492188e-02 -1.72119141e-02  9.17968750e-02  1.39648438e-01\n",
      " -2.39257812e-01 -2.11914062e-01 -2.21679688e-01  1.53320312e-01\n",
      " -1.58691406e-02 -2.00195312e-01 -2.07519531e-02  3.58886719e-02\n",
      " -6.96629286e-07 -2.13867188e-01  2.00195312e-01 -1.09375000e-01\n",
      " -5.15136719e-02  6.22558594e-02 -3.22265625e-01 -7.86132812e-02\n",
      "  5.02929688e-02  7.08007812e-02  1.20117188e-01 -1.79687500e-01\n",
      "  1.59179688e-01 -1.02233887e-03 -3.49609375e-01  1.25000000e-01\n",
      "  6.44531250e-02  8.10546875e-02 -3.39355469e-02  7.42187500e-02\n",
      " -3.08837891e-02 -1.38671875e-01 -3.19824219e-02  1.99218750e-01\n",
      "  1.25000000e-01  5.68847656e-02 -1.67968750e-01  1.30859375e-01\n",
      "  2.90527344e-02 -1.49536133e-02 -1.39648438e-01  4.07714844e-02\n",
      " -1.05590820e-02 -1.74804688e-01  2.12890625e-01 -1.41601562e-01\n",
      "  2.30712891e-02 -3.36914062e-02 -8.78906250e-02 -6.64062500e-02\n",
      " -6.93359375e-02 -7.42187500e-02  7.03125000e-02 -2.01416016e-02\n",
      " -1.26953125e-01 -3.63769531e-02  5.93261719e-02  1.18164062e-01\n",
      " -6.34765625e-03 -7.42187500e-02  3.19824219e-02  6.68945312e-02\n",
      " -2.27539062e-01  6.54296875e-02  1.79443359e-02  1.46484375e-01\n",
      " -5.49316406e-02 -1.15234375e-01 -2.16796875e-01  8.74023438e-02\n",
      "  2.61718750e-01  1.54296875e-01  6.71386719e-03 -2.78320312e-02\n",
      " -4.15039062e-03 -2.09960938e-02 -5.51757812e-02 -9.76562500e-03\n",
      " -1.29882812e-01  1.31835938e-01 -8.42285156e-03  2.29492188e-01\n",
      "  1.78710938e-01  1.94335938e-01  4.68750000e-02  2.18505859e-02\n",
      " -2.75878906e-02  1.73828125e-01  1.33789062e-01  1.36718750e-01\n",
      "  3.10546875e-01  9.39941406e-03  9.22851562e-02 -2.44140625e-01\n",
      " -5.10253906e-02  7.81250000e-02 -1.43554688e-01  9.17968750e-02\n",
      "  2.96630859e-02  9.46044922e-03 -2.04101562e-01  1.60156250e-01\n",
      "  1.43554688e-01 -2.02636719e-02  2.13623047e-02 -6.98242188e-02\n",
      " -3.11279297e-03 -2.52685547e-02 -1.09863281e-01  1.07910156e-01\n",
      " -7.03125000e-02 -1.27929688e-01 -5.07812500e-02  4.27246094e-02\n",
      " -7.32421875e-02 -3.54003906e-02  8.88671875e-02 -3.02734375e-01]\n"
     ]
    }
   ],
   "source": [
    "# word example 1\n",
    "\n",
    "word = 'happy'\n",
    "\n",
    "# print similar words to a given word  \n",
    "print(\"Similar words to the word\", word, \"are\", w2v_model.most_similar(word))\n",
    "\n",
    "# print the vector size of a word \n",
    "print(len(w2v_model[word]))\n",
    "\n",
    "# print the vector of the word \n",
    "print(w2v_model[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2014593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar words to the word egypt are [('syria', 0.6730753183364868), ('saudi_arabia', 0.6684698462486267), ('bahrain', 0.6469383239746094), ('ethiopia', 0.6380573511123657), ('#_Jan##', 0.6275482773780823), ('syrian', 0.6245205998420715), ('yemen', 0.6230114698410034), ('saudi', 0.6178266406059265), ('lebanon', 0.6116478443145752), ('arabia', 0.6031927466392517)]\n",
      "300\n",
      "[ 3.12500000e-02  1.12792969e-01  1.14746094e-01  3.55468750e-01\n",
      " -2.24609375e-01 -5.73730469e-02 -6.34765625e-02 -6.10351562e-02\n",
      "  3.93066406e-02  1.01562500e-01 -1.67968750e-01 -3.63281250e-01\n",
      " -2.15820312e-01 -6.00585938e-02 -3.80859375e-02  8.64257812e-02\n",
      " -7.32421875e-02  1.08398438e-01  9.17968750e-02  3.85742188e-02\n",
      "  1.25976562e-01 -2.22656250e-01  3.53515625e-01 -4.19921875e-02\n",
      " -8.10546875e-02  1.39648438e-01 -1.47460938e-01  2.41210938e-01\n",
      "  2.96875000e-01 -1.66992188e-01 -2.20947266e-02 -7.27539062e-02\n",
      " -2.36328125e-01 -1.25885010e-03 -2.94921875e-01  2.08984375e-01\n",
      " -2.13867188e-01  1.09375000e-01 -1.00585938e-01 -8.39843750e-02\n",
      " -1.08398438e-01  6.39648438e-02  1.87500000e-01  7.56835938e-02\n",
      "  3.14453125e-01 -2.58789062e-02 -1.30859375e-01 -2.89916992e-03\n",
      " -2.48046875e-01 -1.36718750e-01 -2.47070312e-01 -1.31835938e-01\n",
      "  4.78515625e-02  2.31445312e-01 -6.98242188e-02  5.54199219e-02\n",
      " -4.51171875e-01  2.38281250e-01 -3.96728516e-03 -2.50000000e-01\n",
      " -1.37695312e-01 -3.58886719e-02 -1.00585938e-01  8.00781250e-02\n",
      " -1.32812500e-01 -4.58984375e-01 -9.17968750e-02 -2.89062500e-01\n",
      " -3.34472656e-02 -2.28515625e-01 -2.08984375e-01  3.57421875e-01\n",
      "  4.22363281e-02 -5.07812500e-02 -7.47070312e-02 -1.83593750e-01\n",
      "  2.23388672e-02 -1.42822266e-02 -1.38671875e-01  2.52685547e-02\n",
      " -7.71484375e-02 -4.54101562e-02 -1.11816406e-01 -2.63671875e-01\n",
      "  1.99218750e-01  1.20239258e-02  3.76892090e-03  1.31835938e-01\n",
      " -8.34960938e-02  1.45507812e-01  9.96093750e-02 -1.51367188e-01\n",
      " -3.26171875e-01 -1.61132812e-02  1.03149414e-02  3.61328125e-02\n",
      " -1.40625000e-01 -2.48046875e-01  4.90234375e-01  1.85546875e-01\n",
      " -1.15234375e-01  9.17968750e-02 -1.23901367e-02 -1.09375000e-01\n",
      " -1.15722656e-01  2.67578125e-01 -1.52343750e-01 -9.42382812e-02\n",
      " -9.57031250e-02 -1.18652344e-01 -5.34667969e-02 -2.41210938e-01\n",
      "  2.92968750e-01 -2.44140625e-01 -1.66015625e-01 -3.93066406e-02\n",
      "  7.12890625e-02 -1.12304688e-01  6.20117188e-02 -1.63085938e-01\n",
      " -1.20239258e-02 -3.51562500e-02  7.86132812e-02 -1.38671875e-01\n",
      "  6.17675781e-02 -1.22070312e-01 -5.27343750e-02  2.01171875e-01\n",
      " -1.81884766e-02  4.02832031e-02 -1.34765625e-01  1.96289062e-01\n",
      "  2.18750000e-01  4.63867188e-02  5.41992188e-02 -4.97436523e-03\n",
      " -2.38281250e-01 -2.33398438e-01  9.81445312e-02  1.43554688e-01\n",
      "  4.29687500e-01 -3.49121094e-02  1.22558594e-01 -2.31445312e-01\n",
      " -8.30078125e-02 -7.91015625e-02  2.52685547e-02  7.47070312e-02\n",
      "  1.62109375e-01 -2.31445312e-01  4.21875000e-01 -3.53515625e-01\n",
      " -9.47265625e-02 -3.24218750e-01 -2.50000000e-01 -1.60156250e-01\n",
      "  2.62451172e-02  7.76367188e-02  5.78613281e-02  1.27929688e-01\n",
      " -2.18750000e-01 -4.10156250e-02 -3.36914062e-02 -1.30859375e-01\n",
      "  2.44140625e-02 -8.88671875e-02 -4.56542969e-02  1.67968750e-01\n",
      " -3.47656250e-01  3.96484375e-01 -3.67187500e-01  1.80664062e-01\n",
      "  5.29785156e-02 -4.56542969e-02  1.03515625e-01  4.33349609e-03\n",
      "  4.14062500e-01 -4.25781250e-01  2.46093750e-01 -2.40234375e-01\n",
      " -1.75781250e-01  7.08007812e-02 -2.24609375e-01 -2.57812500e-01\n",
      " -1.56250000e-02  9.52148438e-02 -6.54296875e-02  7.47070312e-02\n",
      "  7.71484375e-02  4.37011719e-02  4.56542969e-02  3.75000000e-01\n",
      " -2.75390625e-01  5.90820312e-02  3.80859375e-02  1.40625000e-01\n",
      " -3.45703125e-01 -2.55859375e-01  8.17871094e-03 -1.82617188e-01\n",
      " -1.45507812e-01 -3.06396484e-02 -1.88476562e-01 -3.82812500e-01\n",
      " -5.49316406e-02 -8.49609375e-02  1.13769531e-01  7.47070312e-02\n",
      " -2.17773438e-01  1.44531250e-01  1.79443359e-02  4.84375000e-01\n",
      " -2.59765625e-01 -4.39453125e-02 -3.67187500e-01  1.58203125e-01\n",
      "  1.69921875e-01 -6.00585938e-02  1.04980469e-01 -9.57031250e-02\n",
      " -1.04003906e-01 -1.46484375e-01  3.94531250e-01  9.86328125e-02\n",
      "  1.46484375e-01 -9.47265625e-02  2.05078125e-01  3.41796875e-01\n",
      "  2.65625000e-01 -2.42187500e-01 -2.74658203e-02 -2.18750000e-01\n",
      "  1.15722656e-01 -9.17968750e-02  6.64062500e-02 -6.34765625e-03\n",
      "  1.89453125e-01  2.01171875e-01  1.75781250e-01  1.68800354e-04\n",
      "  3.24218750e-01  1.29882812e-01 -2.01416016e-02  2.02148438e-01\n",
      " -6.29882812e-02 -1.68457031e-02 -1.62109375e-01  7.08007812e-02\n",
      " -2.71484375e-01  3.14941406e-02  3.71093750e-01  2.29492188e-01\n",
      "  1.82617188e-01  3.00781250e-01  1.47460938e-01 -3.08593750e-01\n",
      " -2.44140625e-01 -2.81982422e-02  1.90429688e-01 -2.47070312e-01\n",
      "  3.66210938e-02 -3.72314453e-03  1.25000000e-01 -1.00585938e-01\n",
      "  6.00585938e-02 -1.47705078e-02 -2.08984375e-01  1.51977539e-02\n",
      " -8.49609375e-02  8.64257812e-02 -1.52343750e-01  1.34765625e-01\n",
      " -1.71661377e-03 -4.24804688e-02 -1.48315430e-02  2.75878906e-02\n",
      "  1.66015625e-02 -6.15234375e-02 -2.91015625e-01  1.42578125e-01\n",
      "  2.45361328e-02  7.66601562e-02  6.01196289e-03 -3.63769531e-02\n",
      "  1.04980469e-01  5.66406250e-02 -2.12890625e-01  1.39648438e-01\n",
      " -1.57226562e-01 -2.07519531e-03  5.83496094e-02  8.88671875e-02\n",
      " -9.03320312e-02 -1.17187500e-01 -1.79687500e-01 -3.01513672e-02\n",
      " -4.47265625e-01 -1.31835938e-01  9.91210938e-02  3.33984375e-01]\n"
     ]
    }
   ],
   "source": [
    "# word example 2\n",
    "word = 'egypt'\n",
    "\n",
    "# print similar words to a given word  \n",
    "print(\"Similar words to the word\", word, \"are\", w2v_model.most_similar(word))\n",
    "\n",
    "# print the vector size of a word \n",
    "print(len(w2v_model[word]))\n",
    "\n",
    "# print the vector of the word \n",
    "print(w2v_model[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bbbc018",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Key 'practicalnlp' not present\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# What if the word is not in the vocab?\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mw2v_model\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpracticalnlp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\youss\\anaconda3\\envs\\GPU-Pytorch\\lib\\site-packages\\gensim\\models\\keyedvectors.py:403\u001b[0m, in \u001b[0;36mKeyedVectors.__getitem__\u001b[1;34m(self, key_or_keys)\u001b[0m\n\u001b[0;32m    389\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get vector representation of `key_or_keys`.\u001b[39;00m\n\u001b[0;32m    390\u001b[0m \n\u001b[0;32m    391\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    400\u001b[0m \n\u001b[0;32m    401\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key_or_keys, _KEY_TYPES):\n\u001b[1;32m--> 403\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey_or_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    405\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m vstack([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_vector(key) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m key_or_keys])\n",
      "File \u001b[1;32mc:\\Users\\youss\\anaconda3\\envs\\GPU-Pytorch\\lib\\site-packages\\gensim\\models\\keyedvectors.py:446\u001b[0m, in \u001b[0;36mKeyedVectors.get_vector\u001b[1;34m(self, key, norm)\u001b[0m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_vector\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    423\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get the key's vector, as a 1D numpy array.\u001b[39;00m\n\u001b[0;32m    424\u001b[0m \n\u001b[0;32m    425\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    444\u001b[0m \n\u001b[0;32m    445\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 446\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m norm:\n\u001b[0;32m    448\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfill_norms()\n",
      "File \u001b[1;32mc:\\Users\\youss\\anaconda3\\envs\\GPU-Pytorch\\lib\\site-packages\\gensim\\models\\keyedvectors.py:420\u001b[0m, in \u001b[0;36mKeyedVectors.get_index\u001b[1;34m(self, key, default)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m default\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 420\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKey \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not present\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Key 'practicalnlp' not present\""
     ]
    }
   ],
   "source": [
    "# What if the word is not in the vocab?\n",
    "w2v_model['practicalnlp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79132283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word 'practicalnlp' is not in the vocabulary.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    embedding = w2v_model['practicalnlp']\n",
    "except KeyError:\n",
    "    print(\"The word 'practicalnlp' is not in the vocabulary.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d44ddfc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.3.3\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "print(gensim.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b628371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting en-core-web-md==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.7.1/en_core_web_md-3.7.1-py3-none-any.whl (42.8 MB)\n",
      "     ---------------------------------------- 0.0/42.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.3/42.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.5/42.8 MB 1.5 MB/s eta 0:00:28\n",
      "      --------------------------------------- 0.8/42.8 MB 1.6 MB/s eta 0:00:27\n",
      "     - -------------------------------------- 1.3/42.8 MB 1.7 MB/s eta 0:00:25\n",
      "     - -------------------------------------- 1.3/42.8 MB 1.7 MB/s eta 0:00:25\n",
      "     - -------------------------------------- 1.8/42.8 MB 1.6 MB/s eta 0:00:26\n",
      "     - -------------------------------------- 2.1/42.8 MB 1.6 MB/s eta 0:00:26\n",
      "     -- ------------------------------------- 2.6/42.8 MB 1.7 MB/s eta 0:00:25\n",
      "     -- ------------------------------------- 2.6/42.8 MB 1.7 MB/s eta 0:00:25\n",
      "     -- ------------------------------------- 3.1/42.8 MB 1.5 MB/s eta 0:00:26\n",
      "     --- ------------------------------------ 3.4/42.8 MB 1.6 MB/s eta 0:00:26\n",
      "     --- ------------------------------------ 3.7/42.8 MB 1.6 MB/s eta 0:00:25\n",
      "     ---- ----------------------------------- 4.7/42.8 MB 1.7 MB/s eta 0:00:22\n",
      "     ----- ---------------------------------- 5.8/42.8 MB 2.0 MB/s eta 0:00:19\n",
      "     ----- ---------------------------------- 6.0/42.8 MB 2.0 MB/s eta 0:00:19\n",
      "     ----- ---------------------------------- 6.3/42.8 MB 2.0 MB/s eta 0:00:19\n",
      "     ------ --------------------------------- 6.8/42.8 MB 2.0 MB/s eta 0:00:19\n",
      "     ------ --------------------------------- 7.1/42.8 MB 1.9 MB/s eta 0:00:19\n",
      "     ------ --------------------------------- 7.3/42.8 MB 1.9 MB/s eta 0:00:19\n",
      "     ------- -------------------------------- 7.6/42.8 MB 1.9 MB/s eta 0:00:19\n",
      "     ------- -------------------------------- 7.6/42.8 MB 1.9 MB/s eta 0:00:19\n",
      "     ------- -------------------------------- 7.6/42.8 MB 1.9 MB/s eta 0:00:19\n",
      "     ------- -------------------------------- 7.6/42.8 MB 1.9 MB/s eta 0:00:19\n",
      "     ------- -------------------------------- 7.6/42.8 MB 1.9 MB/s eta 0:00:19\n",
      "     ------- -------------------------------- 7.6/42.8 MB 1.9 MB/s eta 0:00:19\n",
      "     ------- -------------------------------- 7.6/42.8 MB 1.9 MB/s eta 0:00:19\n",
      "     ------- -------------------------------- 7.6/42.8 MB 1.9 MB/s eta 0:00:19\n",
      "     -------- ------------------------------- 8.7/42.8 MB 1.5 MB/s eta 0:00:24\n",
      "     -------- ------------------------------- 8.9/42.8 MB 1.5 MB/s eta 0:00:23\n",
      "     -------- ------------------------------- 9.2/42.8 MB 1.5 MB/s eta 0:00:23\n",
      "     --------- ------------------------------ 10.0/42.8 MB 1.5 MB/s eta 0:00:22\n",
      "     ---------- ----------------------------- 11.0/42.8 MB 1.6 MB/s eta 0:00:20\n",
      "     ---------- ----------------------------- 11.3/42.8 MB 1.7 MB/s eta 0:00:20\n",
      "     ---------- ----------------------------- 11.5/42.8 MB 1.7 MB/s eta 0:00:19\n",
      "     ----------- ---------------------------- 12.1/42.8 MB 1.7 MB/s eta 0:00:19\n",
      "     ----------- ---------------------------- 12.3/42.8 MB 1.6 MB/s eta 0:00:19\n",
      "     ------------ --------------------------- 12.8/42.8 MB 1.7 MB/s eta 0:00:19\n",
      "     ------------ --------------------------- 13.4/42.8 MB 1.7 MB/s eta 0:00:18\n",
      "     ------------ --------------------------- 13.6/42.8 MB 1.7 MB/s eta 0:00:18\n",
      "     ------------- -------------------------- 14.2/42.8 MB 1.7 MB/s eta 0:00:17\n",
      "     ------------- -------------------------- 14.2/42.8 MB 1.7 MB/s eta 0:00:17\n",
      "     ------------- -------------------------- 14.4/42.8 MB 1.7 MB/s eta 0:00:18\n",
      "     ------------- -------------------------- 14.7/42.8 MB 1.6 MB/s eta 0:00:18\n",
      "     -------------- ------------------------- 15.2/42.8 MB 1.6 MB/s eta 0:00:17\n",
      "     -------------- ------------------------- 15.5/42.8 MB 1.6 MB/s eta 0:00:17\n",
      "     -------------- ------------------------- 15.7/42.8 MB 1.6 MB/s eta 0:00:17\n",
      "     --------------- ------------------------ 16.3/42.8 MB 1.6 MB/s eta 0:00:17\n",
      "     --------------- ------------------------ 16.5/42.8 MB 1.6 MB/s eta 0:00:17\n",
      "     --------------- ------------------------ 17.0/42.8 MB 1.6 MB/s eta 0:00:16\n",
      "     ---------------- ----------------------- 17.3/42.8 MB 1.7 MB/s eta 0:00:16\n",
      "     ---------------- ----------------------- 17.6/42.8 MB 1.7 MB/s eta 0:00:16\n",
      "     ---------------- ----------------------- 17.6/42.8 MB 1.7 MB/s eta 0:00:16\n",
      "     ---------------- ----------------------- 17.8/42.8 MB 1.6 MB/s eta 0:00:16\n",
      "     ---------------- ----------------------- 17.8/42.8 MB 1.6 MB/s eta 0:00:16\n",
      "     ----------------- ---------------------- 18.6/42.8 MB 1.6 MB/s eta 0:00:16\n",
      "     ----------------- ---------------------- 18.9/42.8 MB 1.6 MB/s eta 0:00:15\n",
      "     ----------------- ---------------------- 19.1/42.8 MB 1.6 MB/s eta 0:00:15\n",
      "     ------------------ --------------------- 19.4/42.8 MB 1.6 MB/s eta 0:00:15\n",
      "     ------------------ --------------------- 19.7/42.8 MB 1.6 MB/s eta 0:00:15\n",
      "     ------------------ --------------------- 19.7/42.8 MB 1.6 MB/s eta 0:00:15\n",
      "     ------------------ --------------------- 20.2/42.8 MB 1.6 MB/s eta 0:00:15\n",
      "     ------------------ --------------------- 20.2/42.8 MB 1.6 MB/s eta 0:00:15\n",
      "     ------------------- -------------------- 20.4/42.8 MB 1.6 MB/s eta 0:00:15\n",
      "     ------------------- -------------------- 20.7/42.8 MB 1.5 MB/s eta 0:00:15\n",
      "     ------------------- -------------------- 20.7/42.8 MB 1.5 MB/s eta 0:00:15\n",
      "     ------------------- -------------------- 21.0/42.8 MB 1.5 MB/s eta 0:00:15\n",
      "     ------------------- -------------------- 21.2/42.8 MB 1.5 MB/s eta 0:00:15\n",
      "     -------------------- ------------------- 21.5/42.8 MB 1.5 MB/s eta 0:00:15\n",
      "     -------------------- ------------------- 21.8/42.8 MB 1.5 MB/s eta 0:00:14\n",
      "     -------------------- ------------------- 22.3/42.8 MB 1.5 MB/s eta 0:00:14\n",
      "     --------------------- ------------------ 22.5/42.8 MB 1.5 MB/s eta 0:00:14\n",
      "     --------------------- ------------------ 22.8/42.8 MB 1.5 MB/s eta 0:00:14\n",
      "     --------------------- ------------------ 23.1/42.8 MB 1.5 MB/s eta 0:00:14\n",
      "     --------------------- ------------------ 23.3/42.8 MB 1.5 MB/s eta 0:00:14\n",
      "     ---------------------- ----------------- 23.6/42.8 MB 1.5 MB/s eta 0:00:13\n",
      "     ---------------------- ----------------- 23.9/42.8 MB 1.5 MB/s eta 0:00:13\n",
      "     ---------------------- ----------------- 24.1/42.8 MB 1.5 MB/s eta 0:00:13\n",
      "     ---------------------- ----------------- 24.4/42.8 MB 1.5 MB/s eta 0:00:13\n",
      "     ----------------------- ---------------- 24.6/42.8 MB 1.5 MB/s eta 0:00:13\n",
      "     ----------------------- ---------------- 24.9/42.8 MB 1.5 MB/s eta 0:00:13\n",
      "     ----------------------- ---------------- 25.2/42.8 MB 1.5 MB/s eta 0:00:12\n",
      "     ----------------------- ---------------- 25.2/42.8 MB 1.5 MB/s eta 0:00:12\n",
      "     ----------------------- ---------------- 25.4/42.8 MB 1.5 MB/s eta 0:00:12\n",
      "     ------------------------ --------------- 25.7/42.8 MB 1.5 MB/s eta 0:00:12\n",
      "     ------------------------ --------------- 26.0/42.8 MB 1.4 MB/s eta 0:00:12\n",
      "     ------------------------ --------------- 26.5/42.8 MB 1.5 MB/s eta 0:00:12\n",
      "     ------------------------- -------------- 27.0/42.8 MB 1.5 MB/s eta 0:00:11\n",
      "     ------------------------- -------------- 27.8/42.8 MB 1.5 MB/s eta 0:00:11\n",
      "     -------------------------- ------------- 28.6/42.8 MB 1.5 MB/s eta 0:00:10\n",
      "     --------------------------- ------------ 29.4/42.8 MB 1.5 MB/s eta 0:00:09\n",
      "     --------------------------- ------------ 29.4/42.8 MB 1.5 MB/s eta 0:00:09\n",
      "     --------------------------- ------------ 29.9/42.8 MB 1.5 MB/s eta 0:00:09\n",
      "     ---------------------------- ----------- 30.7/42.8 MB 1.6 MB/s eta 0:00:08\n",
      "     ----------------------------- ---------- 31.5/42.8 MB 1.6 MB/s eta 0:00:08\n",
      "     ----------------------------- ---------- 31.7/42.8 MB 1.6 MB/s eta 0:00:07\n",
      "     ----------------------------- ---------- 32.0/42.8 MB 1.6 MB/s eta 0:00:07\n",
      "     ------------------------------ --------- 32.2/42.8 MB 1.6 MB/s eta 0:00:07\n",
      "     ------------------------------ --------- 32.5/42.8 MB 1.6 MB/s eta 0:00:07\n",
      "     ------------------------------ --------- 32.8/42.8 MB 1.6 MB/s eta 0:00:07\n",
      "     ------------------------------- -------- 33.3/42.8 MB 1.6 MB/s eta 0:00:07\n",
      "     ------------------------------- -------- 33.6/42.8 MB 1.6 MB/s eta 0:00:06\n",
      "     ------------------------------- -------- 34.1/42.8 MB 1.6 MB/s eta 0:00:06\n",
      "     -------------------------------- ------- 34.9/42.8 MB 1.6 MB/s eta 0:00:05\n",
      "     --------------------------------- ------ 35.4/42.8 MB 1.6 MB/s eta 0:00:05\n",
      "     --------------------------------- ------ 36.2/42.8 MB 1.6 MB/s eta 0:00:05\n",
      "     ---------------------------------- ----- 36.4/42.8 MB 1.6 MB/s eta 0:00:04\n",
      "     ---------------------------------- ----- 37.2/42.8 MB 1.6 MB/s eta 0:00:04\n",
      "     ----------------------------------- ---- 38.0/42.8 MB 1.7 MB/s eta 0:00:03\n",
      "     ------------------------------------ --- 38.5/42.8 MB 1.7 MB/s eta 0:00:03\n",
      "     ------------------------------------ --- 39.1/42.8 MB 1.7 MB/s eta 0:00:03\n",
      "     ------------------------------------ --- 39.1/42.8 MB 1.7 MB/s eta 0:00:03\n",
      "     ------------------------------------ --- 39.3/42.8 MB 1.7 MB/s eta 0:00:03\n",
      "     ------------------------------------ --- 39.3/42.8 MB 1.7 MB/s eta 0:00:03\n",
      "     ------------------------------------- -- 39.8/42.8 MB 1.7 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 41.4/42.8 MB 1.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  41.9/42.8 MB 1.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  42.2/42.8 MB 1.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  42.5/42.8 MB 1.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 42.8/42.8 MB 1.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.2 in c:\\users\\youss\\anaconda3\\envs\\gpu-pytorch\\lib\\site-packages (from en-core-web-md==3.7.1) (3.7.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\youss\\anaconda3\\envs\\gpu-pytorch\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\youss\\anaconda3\\envs\\gpu-pytorch\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\youss\\anaconda3\\envs\\gpu-pytorch\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\youss\\anaconda3\\envs\\gpu-pytorch\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\youss\\anaconda3\\envs\\gpu-pytorch\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\youss\\anaconda3\\envs\\gpu-pytorch\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\youss\\anaconda3\\envs\\gpu-pytorch\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\youss\\anaconda3\\envs\\gpu-pytorch\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\youss\\anaconda3\\envs\\gpu-pytorch\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\youss\\anaconda3\\envs\\gpu-pytorch\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\youss\\anaconda3\\envs\\gpu-pytorch\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.12.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\youss\\anaconda3\\envs\\gpu-pytorch\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (4.67.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\youss\\anaconda3\\envs\\gpu-pytorch\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\youss\\anaconda3\\envs\\gpu-pytorch\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.8.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\youss\\anaconda3\\envs\\gpu-pytorch\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\youss\\anaconda3\\envs\\gpu-pytorch\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (75.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\youss\\anaconda3\\envs\\gpu-pytorch\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\youss\\anaconda3\\envs\\gpu-pytorch\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.4.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\youss\\anaconda3\\envs\\gpu-pytorch\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.24.3)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\youss\\anaconda3\\envs\\gpu-pytorch\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\youss\\anaconda3\\envs\\gpu-pytorch\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\youss\\anaconda3\\envs\\gpu-pytorch\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\youss\\anaconda3\\envs\\gpu-pytorch\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\youss\\anaconda3\\envs\\gpu-pytorch\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\youss\\anaconda3\\envs\\gpu-pytorch\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\youss\\anaconda3\\envs\\gpu-pytorch\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\youss\\anaconda3\\envs\\gpu-pytorch\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2024.8.30)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\youss\\anaconda3\\envs\\gpu-pytorch\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.7.10)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\youss\\anaconda3\\envs\\gpu-pytorch\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.1.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\youss\\anaconda3\\envs\\gpu-pytorch\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\youss\\anaconda3\\envs\\gpu-pytorch\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\youss\\anaconda3\\envs\\gpu-pytorch\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\youss\\anaconda3\\envs\\gpu-pytorch\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (13.9.4)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\youss\\anaconda3\\envs\\gpu-pytorch\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.20.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\youss\\anaconda3\\envs\\gpu-pytorch\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (7.0.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\youss\\anaconda3\\envs\\gpu-pytorch\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.1.3)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in c:\\users\\youss\\anaconda3\\envs\\gpu-pytorch\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\youss\\anaconda3\\envs\\gpu-pytorch\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\youss\\anaconda3\\envs\\gpu-pytorch\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.15.1)\n",
      "Requirement already satisfied: wrapt in c:\\users\\youss\\anaconda3\\envs\\gpu-pytorch\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\youss\\anaconda3\\envs\\gpu-pytorch\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.1.2)\n",
      "Installing collected packages: en-core-web-md\n",
      "Successfully installed en-core-web-md-3.7.1\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_md\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc78dc0",
   "metadata": {},
   "source": [
    "##  Getting the embedding representation for full text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1037e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.12132597e+00  3.35791826e+00 -1.37670004e+00  2.12385988e+00\n",
      "  6.28810024e+00  3.22182178e-01  1.18766809e+00  4.87165976e+00\n",
      "  2.24417591e+00  7.14037895e-01  1.03926411e+01  8.83959949e-01\n",
      " -1.73903596e+00  5.41560054e-01 -1.55289978e-01  5.18263149e+00\n",
      "  1.30475593e+00  4.21266031e+00 -5.92720024e-02 -1.28370404e+00\n",
      "  2.54464006e+00  1.31399959e-01 -4.84842014e+00  1.84918189e+00\n",
      " -6.28175914e-01 -1.20439982e+00 -1.89999998e+00 -4.88359404e+00\n",
      " -1.59767210e+00 -2.89982986e+00  2.57135957e-01  2.57717991e+00\n",
      " -2.17529225e+00 -2.77516985e+00 -2.83998394e+00  8.96261990e-01\n",
      "  3.73915970e-01  4.36887592e-01  2.06502008e+00 -2.08246017e+00\n",
      " -7.68391967e-01  1.87826610e+00  1.21900201e+00  4.61789995e-01\n",
      " -2.57270002e+00  2.26117969e+00  2.93105793e+00 -1.84933782e+00\n",
      " -5.98986030e-01  1.39556003e+00 -1.71248794e+00  4.13538039e-01\n",
      "  2.05463791e+00 -4.33485985e+00 -3.63799959e-01 -1.03273201e+00\n",
      "  2.23117399e+00 -5.93478978e-01 -7.95660019e-01  3.38980108e-01\n",
      "  2.17601585e+00 -9.78588223e-01  1.59391606e+00 -5.44664025e-01\n",
      "  5.25560021e-01  2.36829996e-01 -2.71454000e+00 -4.09956551e+00\n",
      "  3.58861995e+00  1.88228393e+00 -1.32360369e-01  2.62365842e+00\n",
      " -5.64063978e+00  1.85808206e+00 -1.57176018e-01  2.28739977e+00\n",
      " -4.46452236e+00  4.26639557e+00 -2.69448996e+00 -5.19786000e-01\n",
      " -6.90577984e+00 -2.15198779e+00  3.10798001e+00  1.20732009e-01\n",
      "  2.46033001e+00  7.85449982e-01 -1.71056592e+00 -1.36477208e+00\n",
      "  5.16162777e+00 -3.87644005e+00 -8.30022037e-01 -4.95620394e+00\n",
      "  1.40970004e+00 -5.66209984e+00  3.92910153e-01 -1.75315022e+00\n",
      "  1.34713590e+00 -1.55021951e-01 -1.65660053e-01 -2.35177064e+00\n",
      "  2.20533991e+00 -1.27289966e-01  4.31172848e+00  6.06594181e+00\n",
      "  6.12536013e-01  5.33462048e+00  1.51661408e+00 -1.01797585e-03\n",
      " -1.92552590e+00 -5.09810150e-01  2.12677985e-01  5.43400574e+00\n",
      " -1.59323001e+00  2.02191997e+00 -6.46942019e-01 -1.34048009e+00\n",
      " -2.40258002e+00 -9.42901596e-02  1.53503990e+00  7.11719990e-01\n",
      " -1.41200021e-01 -1.53452587e+00 -1.28749922e-01  5.79495955e+00\n",
      " -3.98874974e+00 -8.87574005e+00 -2.63187861e+00 -2.43716979e+00\n",
      "  5.15329981e+00 -1.02950191e+00 -3.10627413e+00  7.89476037e-01\n",
      "  7.70247936e+00 -3.11397982e+00  9.70444024e-01  1.30023801e+00\n",
      "  2.48048615e+00 -3.09959978e-01  1.73424792e+00 -3.05760002e+00\n",
      " -3.40968013e+00  1.37093997e+00  2.51245403e+00  3.81690788e+00\n",
      "  2.03780603e+00  2.34504032e+00 -5.21864033e+00 -2.09663957e-01\n",
      " -6.18432164e-01  4.32332993e+00  9.76016879e-01  3.86202431e+00\n",
      "  9.37544048e-01  2.95846009e+00  4.35576022e-01  1.30239010e+00\n",
      "  4.32818842e+00  3.40309834e+00  1.50590396e+00 -2.03830004e+00\n",
      " -1.92513597e+00 -2.70414877e+00  3.97877192e+00  2.97642970e+00\n",
      " -3.31784821e+00 -1.32754195e+00 -3.58762813e+00  6.66141415e+00\n",
      "  3.15059996e+00 -6.01970017e-01  1.77874792e+00 -1.07966197e+00\n",
      "  1.93808782e+00  2.55996418e+00 -2.91692078e-01 -2.80427074e+00\n",
      "  1.44629985e-01 -6.88903987e-01 -2.90776587e+00 -1.83229005e+00\n",
      " -1.89886606e+00  2.93070602e+00 -1.23262000e+00 -1.69910777e+00\n",
      " -3.62026024e+00  3.90502036e-01 -1.55681002e+00  1.14068007e+00\n",
      " -4.04799469e-02  3.93695188e+00 -4.22640562e-01 -1.93146002e+00\n",
      " -5.19394040e-01 -2.51767963e-01  3.25182796e+00  2.74722219e+00\n",
      " -4.17668009e+00 -2.02020001e+00  1.68449402e+00 -1.86216009e+00\n",
      "  1.25042415e+00 -2.28191996e+00 -2.33069587e+00 -2.48664427e+00\n",
      "  3.63572001e+00 -3.79996304e-03 -6.64441967e+00  2.56701994e+00\n",
      " -2.21361995e+00 -2.46815348e+00  3.89424014e+00  3.45121908e+00\n",
      " -2.41766000e+00  1.15152001e+00  3.82792425e+00 -8.09380054e-01\n",
      "  3.24090004e+00 -5.37707996e+00 -2.96215606e+00  8.50148022e-01\n",
      " -2.52746677e+00 -1.54838085e-01  1.22176385e+00 -2.55283642e+00\n",
      " -4.50680077e-01 -7.63504148e-01  7.89702058e-01  1.06408000e+00\n",
      "  2.70035982e+00 -1.50781989e+00  3.62466002e+00 -4.86896658e+00\n",
      "  2.06970000e+00  4.49000025e+00 -3.77470827e+00 -1.11603975e-01\n",
      "  2.53019989e-01 -2.26199794e+00  1.02542198e+00  4.21261966e-01\n",
      "  1.91147995e+00  1.38655198e+00  2.24793792e+00  3.25494003e+00\n",
      " -3.16287208e+00 -1.52848411e+00 -4.01620007e+00  8.72895896e-01\n",
      "  6.52028084e-01  4.53908253e+00  4.41521823e-01 -3.05549979e+00\n",
      " -6.76350021e+00 -4.69893026e+00 -3.66139978e-01 -3.93597984e+00\n",
      "  3.00554013e+00  1.44500399e+00  1.72780001e+00 -5.92418015e-01\n",
      "  9.56618786e-02  6.05334997e+00  3.10834002e+00  4.81194353e+00\n",
      " -6.30644023e-01  1.15452725e-02 -1.04127908e+00  2.49694395e+00\n",
      " -4.76569986e+00  7.41042018e-01  4.59913921e+00 -3.28753948e-01\n",
      "  8.01228046e-01 -3.16064024e+00  1.73727798e+00 -3.12879950e-01\n",
      "  1.00365996e+00  1.26208007e+00 -1.51870799e+00 -2.73660004e-01\n",
      "  1.94010413e+00 -3.14803815e+00 -8.17219913e-01 -1.48570299e+00\n",
      "  6.32309818e+00 -9.83118862e-02  4.28912067e+00  9.18255985e-01\n",
      " -2.98957396e+00  1.84825003e+00  7.19900131e-01 -4.80681986e-01\n",
      " -2.74291992e-01  2.52313590e+00 -1.54474199e+00  3.27700996e+00\n",
      "  1.01817477e+00 -6.62093997e-01 -3.60317421e+00  4.67279959e+00]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# the pre-trained en_core_web_md model from spaCy, is a medium-sized English model \n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "# process a sentence using the model\n",
    "mydoc = nlp(\"Canada is a large country\")\n",
    "\n",
    "#Get a vector for individual words\n",
    "#print(mydoc[0].vector) \n",
    "\n",
    "#Averaged vector for the entire sentence\n",
    "print(mydoc.vector) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43e33a23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'spacy.lang.en.English'>\n",
      "[-1.7132499e+00  2.1462150e+00  3.3822498e-01  2.0327001e+00\n",
      "  5.3187499e+00  1.8000075e+00 -2.0949826e+00  2.2298698e+00\n",
      "  2.9685848e+00  8.7786734e-01  8.4832745e+00 -1.1373749e+00\n",
      " -8.3087504e-01  2.6968000e+00  8.5587001e-01  3.7318499e+00\n",
      " -4.0461001e+00  2.3709500e+00  1.3235799e+00 -2.2868550e+00\n",
      "  1.8101726e+00 -7.2573203e-01 -6.5917253e+00  3.0008998e+00\n",
      " -2.0096049e+00 -2.7405250e-01 -2.8172500e+00 -1.7489295e+00\n",
      " -1.4400675e+00  2.9781849e+00  1.3113000e+00  1.4226499e+00\n",
      " -3.1205325e+00 -2.5082126e+00 -6.3439498e+00  1.7815149e+00\n",
      " -2.7906446e+00  1.6620250e+00 -2.6334248e+00 -1.9140749e+00\n",
      " -1.8885126e+00  2.8848727e+00  2.4469256e+00 -5.5959249e-01\n",
      " -1.6943649e+00  4.5974746e+00  2.8030751e+00 -2.6699748e+00\n",
      "  1.4377401e+00 -1.5139849e+00 -4.1388702e+00 -5.8904994e-01\n",
      "  1.4429899e+00 -5.8204503e+00  6.7606497e-01  2.9370501e+00\n",
      " -2.0968509e-01 -1.2333748e+00 -2.1224422e+00  3.7628624e+00\n",
      " -3.1993122e+00 -6.3285499e+00  1.3901999e+00 -2.3185003e-01\n",
      "  2.8496499e+00 -1.1528757e-01 -1.3819969e+00  2.6877499e-01\n",
      "  2.3538227e+00  8.3920753e-01 -2.0632849e+00  2.7532125e+00\n",
      " -3.7493575e+00  1.9599401e+00  1.6698799e+00  2.9650674e+00\n",
      " -3.9098749e+00  6.2091746e+00 -3.8015676e+00  3.2519851e+00\n",
      " -1.9985075e+00  3.2185006e-01  9.1072255e-01 -1.3479600e+00\n",
      "  5.3267503e+00  4.4641745e-01 -5.7009749e+00 -2.7347550e+00\n",
      "  2.5000975e+00 -2.0776250e+00 -7.0499992e-01 -3.3263726e+00\n",
      "  2.3192997e+00 -5.3402452e+00 -2.3461363e+00 -1.5317001e+00\n",
      " -1.6335150e+00 -2.2117825e+00 -1.5088301e+00 -2.3774498e+00\n",
      "  3.5609775e+00  1.9679993e-01  5.4026995e+00  4.8314500e+00\n",
      "  9.8821747e-01  3.8438001e+00  3.5808802e+00 -9.7636247e-01\n",
      " -6.6883242e-01 -7.4430758e-01  3.5369495e-01  4.1097250e+00\n",
      " -3.9835000e+00  1.9615051e+00  3.4726224e+00 -2.2103610e+00\n",
      " -1.9338551e+00  2.5943203e+00 -6.8310487e-01  5.0869995e-01\n",
      "  5.1280004e-01 -2.4052999e+00  2.0288975e+00  3.8836999e+00\n",
      " -1.9602450e+00 -6.7609253e+00 -1.2093751e+00 -3.4092624e+00\n",
      "  2.3907452e+00 -9.7977251e-01 -2.1303251e+00  2.8983150e+00\n",
      "  4.0176001e+00 -2.6274395e+00  6.6779995e-01  2.7081501e-01\n",
      " -7.5919998e-01  1.6924500e+00 -8.9730006e-01 -3.5412924e+00\n",
      " -1.3107035e+00 -3.7574499e+00  1.5088400e+00  5.3219998e-01\n",
      "  5.3035078e+00  1.6965001e+00 -6.6798000e+00 -2.1152549e+00\n",
      "  3.2806757e-01  2.9697750e+00  3.2093501e+00  2.1847074e+00\n",
      "  8.2199746e-01  8.9465499e-01 -1.9778825e+00  4.0886998e-01\n",
      "  1.2416000e+00  1.3445500e+00 -2.0772499e-01 -4.0567503e+00\n",
      " -4.0776503e-01  1.5104371e-01  8.7562501e-01  4.3712626e+00\n",
      " -5.6117001e+00 -2.2369425e+00 -1.6614679e+00  2.6710501e+00\n",
      "  1.6513426e+00  1.8339250e+00  1.1698200e+00  2.7016008e-01\n",
      " -1.0893506e-01  2.2442751e+00 -1.3321575e+00 -1.8022101e+00\n",
      " -1.1773200e+00  2.8017027e+00 -5.5006251e+00 -2.0351501e+00\n",
      " -2.4569650e+00  5.1399002e+00 -3.2048249e-01  9.5077515e-01\n",
      " -2.2116249e+00  1.0648500e+00 -8.7851000e-01  2.4892752e+00\n",
      " -1.6987491e-01 -6.3593990e-01  1.6321000e+00 -5.5700498e+00\n",
      "  2.6238163e+00 -2.8422680e+00  1.6626248e+00  4.7771749e+00\n",
      " -2.2643900e+00  3.5781302e+00  2.8506026e+00 -1.6775072e-02\n",
      "  8.9999998e-01 -3.1599995e-01 -5.9687495e-01 -2.0544550e+00\n",
      "  8.0939245e+00 -8.4225756e-01 -7.9929299e+00  2.2685249e+00\n",
      " -2.6107750e+00 -5.8507502e-02  5.2009754e+00  4.6100502e+00\n",
      "  1.3662751e+00  2.5826249e+00  3.2319598e+00  5.6212747e-01\n",
      " -1.7565274e+00 -2.2115002e+00  2.4638927e+00 -1.2793324e+00\n",
      " -2.4019976e+00  7.4424922e-02  1.2330999e+00 -3.9383495e-01\n",
      " -5.3855000e+00  4.6373230e-01  7.5168252e-01  2.4625752e+00\n",
      "  8.1602502e-01  8.2216012e-01  5.1285248e+00  2.8471699e+00\n",
      "  3.0805850e+00  5.9226003e+00 -3.8519952e+00  4.9446254e+00\n",
      " -2.1012001e+00 -5.5081654e+00 -5.9982252e-01 -7.1146256e-01\n",
      " -3.2551250e+00  8.3015025e-02  1.7817001e+00  6.3664997e-01\n",
      " -4.2669401e+00 -7.4108082e-01 -9.9877000e-01  3.5834773e+00\n",
      "  5.7352006e-01  6.4206252e+00  2.1276627e+00 -2.8097000e+00\n",
      " -4.5100503e+00 -1.8715000e+00  3.9398251e+00 -1.9006000e+00\n",
      "  3.6026750e+00  6.0498714e-04  2.6574001e+00  1.9158275e+00\n",
      " -1.5151551e+00  7.4452500e+00  2.1096449e+00  4.5955448e+00\n",
      "  2.8919749e+00 -3.1966248e-01 -2.4237499e+00  7.4282825e-01\n",
      " -2.4896722e+00 -1.1869500e+00  5.3086748e+00 -1.4173927e+00\n",
      "  2.0902500e+00 -5.4872751e+00  3.9635000e+00  3.4208748e-01\n",
      "  4.4739246e+00 -2.0904999e+00  1.1704750e+00  3.2940750e+00\n",
      "  2.1676950e+00 -2.3550699e+00  1.1316501e+00 -1.2893063e+00\n",
      "  2.7938046e+00  3.0386751e+00  2.3843250e+00  3.3839500e-01\n",
      "  6.8431002e-01  9.4634509e-01  5.1540003e+00 -2.2060251e+00\n",
      "  1.6587996e-01  3.3279997e-01 -4.7846001e-01  4.4264250e+00\n",
      " -8.1978500e-01 -3.5249574e+00 -2.8041549e+00  1.5818751e+00]\n",
      "Similarity between 'Egypt is in Africa' and 'Australia is a continent': 0.70\n",
      "Similarity between 'Egypt is in Africa' and 'Japan is in Asia': 0.92\n",
      "Similarity between 'Egypt is in Africa' and 'cat loves dogs': 0.01\n",
      "Similarity between 'Egypt is in Africa' and 'Canada is a cold country': 0.67\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = spacy.load('en_core_web_md')\n",
    "print(type(model))\n",
    "\n",
    "# Define the target sentence\n",
    "target_sentence = \"Egypt is in Africa\"\n",
    "target_doc = model(target_sentence)\n",
    "print(target_doc.vector)\n",
    "\n",
    "# Define a list of candidate sentences\n",
    "candidate_sentences = [\"Australia is a continent\", \n",
    "                       \"Japan is in Asia\", \n",
    "                       \"cat loves dogs\", \n",
    "                       \"Canada is a cold country\"]\n",
    "\n",
    "# Compute the similarity between the target sentence and each candidate sentence\n",
    "for candidate_sentence in candidate_sentences:\n",
    "    candidate_doc = model(candidate_sentence)\n",
    "    similarity = target_doc.similarity(candidate_doc)\n",
    "    print(f\"Similarity between '{target_sentence}' and '{candidate_sentence}': {similarity:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU-Pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "341.333px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
